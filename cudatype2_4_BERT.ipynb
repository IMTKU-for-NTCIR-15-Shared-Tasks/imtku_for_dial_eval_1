{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/tianjianjiang/imtku_for_dial_eval_1/blob/master/cudatype2_4_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check List\n",
    "\n",
    "- [ ] Exercise 0: [Attribute](#Attribute)\n",
    "- [ ] Exercise 1: [Always check the warnings](#scrollTo=ctVODCjcw0kf)\n",
    "- [ ] Exercise 3: [Which version of TF?](#scrollTo=9UIufWQedr9R)\n",
    "- [ ] Exercise 4: What are other issues of this notebook?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribute\n",
    "\n",
    "What are the sources of the code snippets here?\n",
    "\n",
    "Attribution is almost always the first rule to use open sourced materials.\n",
    "\n",
    "It is also the basic academic integrity.\n",
    "\n",
    "Not to mention it is ultimately for our short memory's sake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure GPU spec; T4 is preferred for colab and one can change it for another env.\n",
    "NVIDIA_SMI_PATHS = !which nvidia-smi\n",
    "GPU_LIST = []\n",
    "if NVIDIA_SMI_PATHS:\n",
    "    GPU_LIST = !nvidia-smi -L\n",
    "if not GPU_LIST:\n",
    "  print('On CPU because `nvidia-smi` is not found.')\n",
    "elif not GPU_LIST[0].startswith('GPU 0: Tesla T4'):\n",
    "  display(GPU_LIST)\n",
    "  print('For Colab, if T4 is preferred, please Factory reset runtime until it is.')\n",
    "else:\n",
    "  display(GPU_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defaults\n",
    "\n",
    "Ensure no surprises from conflict packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -U pip\n",
    "!pip3 check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capture logs to prevent them from consuming network bandwidth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture pip_logs\n",
    "!pip3 install -U datascience albumentations coveralls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the captured logs and then check the package dependencies again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(captured_logs):\n",
    "  colab_vnd = 'application/vnd.colab-display-data+json'\n",
    "  for o in captured_logs.outputs:\n",
    "    if colab_vnd in o.data and 'pip_warning' in o.data[colab_vnd]:\n",
    "      o.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify(pip_logs)\n",
    "!pip3 check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which version of TF?\n",
    "\n",
    "It doesn't seem required, and many models are still using TF1.\n",
    "\n",
    "If they are used somewhere, please be explicit.\n",
    "\n",
    "Also, TF2 contains both CPU and GPU parts now, no need to specify `tensorflow-gpu` anymore, just `tensorflow`.\n",
    "\n",
    "**If the required version is TF1, just `tensorflow-gpu` won't suffice, one must also specify a version number.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture pip_tensorflow_and_transformer_logs\n",
    "!pip3 install -U tensorflow-gpu transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify(pip_tensorflow_and_transformer_logs)\n",
    "!pip3 check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HuggingFace Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture pip_py_transformers_logs\n",
    "!pip3 install pytorch-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify(pip_py_transformers_logs)\n",
    "!pip3 check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from pathlib import Path\n",
    "\n",
    "from google.colab import drive\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
    "                              TensorDataset)\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from pytorch_transformers import (WEIGHTS_NAME, BertConfig,\n",
    "                                  BertForQuestionAnswering, BertTokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLAB_CONTENT_DIR_P = Path('/content')\n",
    "GD_DIR_P = COLAB_CONTENT_DIR_P / 'gdrive'\n",
    "drive.mount(str(GD_DIR_P), force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRJ_NAME = 'imtku_dial_eval_1'\n",
    "\n",
    "BASE_DIR_P = GD_DIR_P / f'My Drive/{PRJ_NAME}'\n",
    "BASE_DIR_P.mkdir(parents=True, exist_ok=True)\n",
    "DATA_DIR_P = BASE_DIR_P / 'data'\n",
    "DATA_DIR_P.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "%cd \"{DATA_DIR_P}\"\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Files\n",
    "\n",
    "此處為導入資料集並丟入訓練模型的載入資料部分 完成後會刪除\n",
    "\n",
    "@tianjianjian: when and where did the deletion happen? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf bert-chinese-qa*\n",
    "!wget -q --no-check-certificate -r 'https://drive.google.com/uc?export=download&id=1GQtGFd-1AvZHZuYckhA3xqvvpDk-x5DW' -O bert-chinese-qa.zip\n",
    "!unzip bert-chinese-qa.zip -d bert-chinese-qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/stg880631/BERT-Practice.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls -R #https://github.com/stg880631/BERT-Practice.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PdContestQuestion_A=pd.read_json(f'{DATA_DIR_P}/BERT-Practice/FGC_release_A.json')\n",
    "PdContestQuestion_A.head(10)\n",
    "#print(PdContestQuestion_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PdContestAnswers_A=pd.read_json(f'{DATA_DIR_P}/BERT-Practice/FGC_release_A_answers.json')\n",
    "#print(PdContestAnswers_A)\n",
    "\n",
    "#PdContestQuestion_B=pd.read_json('./BERT-Practice/FGC_release_B.json')\n",
    "#print(PdContestQuestion_B)\n",
    "\n",
    "#PdContestAnswers_B=pd.read_json('./BERT-Practice/FGC_release_B_answers.json')\n",
    "#print(PdContestAnswers_B)\n",
    "\n",
    "#PdTrainFirst=pd.read_json('./BERT-Practice/DRCD_dev.json')\n",
    "#print(PdTrainFirst)\n",
    "\n",
    "#PdTrainSecond=pd.read_json('./BERT-Practice/DRCD_test.json')\n",
    "#print(PdTrainSecond)\n",
    "\n",
    "#PdTrainThird=pd.read_json('./BERT-Practice/DRCD_training.json')\n",
    "#print(PdTrainThird)\n",
    "\n",
    "PdCSV=pd.read_csv(f'{DATA_DIR_P}/BERT-Practice/FGC_release_A_1.csv', encoding = 'big5')\n",
    "\n",
    "#pd.get_dummies  # @tianjianjiang: what was the purpose of this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are those functions for?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_list(tensor):\n",
    "    return tensor.detach().cpu().tolist()\n",
    " \n",
    "\n",
    "def _get_best_indexes(logits, n_best_size=1):\n",
    "    \"\"\"Get the n-best logits from a list.\"\"\"\n",
    "    index_and_score = sorted(enumerate(logits), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    best_indexes = []\n",
    "    for i in range(len(index_and_score)):\n",
    "        if i >= n_best_size:\n",
    "            break\n",
    "        best_indexes.append(index_and_score[i][0])\n",
    "    return best_indexes\n",
    " \n",
    "\n",
    "def evaluate(dataset, model, tokenizer):\n",
    "    eval_sampler = SequentialSampler(dataset)\n",
    "    eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=1)\n",
    "\n",
    "    # Eval!\n",
    "    all_results = []\n",
    "    for batch in eval_dataloader:\n",
    "        model.eval()\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        with torch.no_grad():\n",
    "            inputs = {'input_ids':      batch[0],\n",
    "                      'attention_mask': batch[1],\n",
    "                      'token_type_ids': batch[2],\n",
    "                      }\n",
    "            example_indices = batch[3]\n",
    "            outputs = model(**inputs)\n",
    "            start_logits = to_list(outputs[0][0])\n",
    "            end_logits   = to_list(outputs[1][0])\n",
    "            start_indexes = _get_best_indexes(start_logits)\n",
    "            end_indexes = _get_best_indexes(end_logits)\n",
    "    return (start_indexes, end_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_is_max_context(doc_spans, cur_span_index, position):\n",
    "    \"\"\"Check if this is the 'max context' doc span for the token.\"\"\"\n",
    "\n",
    "    # Because of the sliding window approach taken to scoring documents, a single\n",
    "    # token can appear in multiple documents. E.g.\n",
    "    #  Doc: the man went to the store and bought a gallon of milk\n",
    "    #  Span A: the man went to the\n",
    "    #  Span B: to the store and bought\n",
    "    #  Span C: and bought a gallon of\n",
    "    #  ...\n",
    "    #\n",
    "    # Now the word 'bought' will have two scores from spans B and C. We only\n",
    "    # want to consider the score with \"maximum context\", which we define as\n",
    "    # the *minimum* of its left and right context (the *sum* of left and\n",
    "    # right context will always be the same, of course).\n",
    "    #\n",
    "    # In the example the maximum context for 'bought' would be span C since\n",
    "    # it has 1 left context and 3 right context, while span B has 4 left context\n",
    "    # and 0 right context.\n",
    "    best_score = None\n",
    "    best_span_index = None\n",
    "    for (span_index, doc_span) in enumerate(doc_spans):\n",
    "        end = doc_span.start + doc_span.length - 1\n",
    "        if position < doc_span.start:\n",
    "            continue\n",
    "        if position > end:\n",
    "            continue\n",
    "        num_left_context = position - doc_span.start\n",
    "        num_right_context = end - position\n",
    "        score = min(num_left_context, num_right_context) + 0.01 * doc_span.length\n",
    "        if best_score is None or score > best_score:\n",
    "            best_score = score\n",
    "            best_span_index = span_index\n",
    "\n",
    "    return cur_span_index == best_span_index\n",
    "\n",
    "\n",
    "def convert_examples_to_features(tokenizer, question_text, doc_tokens, max_seq_length=384,\n",
    "                                 doc_stride=1, max_query_length=35,\n",
    "                                 cls_token_at_end=False,\n",
    "                                 cls_token='[CLS]', sep_token='[SEP]', pad_token=0,\n",
    "                                 sequence_a_segment_id=0, sequence_b_segment_id=1,\n",
    "                                \n",
    "                                 cls_token_segment_id=0, pad_token_segment_id=0,\n",
    "                                 mask_padding_with_zero=True):\n",
    "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "    query_tokens = tokenizer.tokenize(question_text)\n",
    "    #print(query_tokens)(test)\n",
    "    if len(query_tokens) > max_query_length:\n",
    "      query_tokens = query_tokens[0:max_query_length]\n",
    "    tok_to_orig_index = []\n",
    "    orig_to_tok_index = []\n",
    "    all_doc_tokens = []\n",
    "    for (i, token) in enumerate(doc_tokens):\n",
    "        orig_to_tok_index.append(len(all_doc_tokens))\n",
    "        sub_tokens = tokenizer.tokenize(token)\n",
    "        for sub_token in sub_tokens:\n",
    "            tok_to_orig_index.append(i)\n",
    "            all_doc_tokens.append(sub_token)#turn DTEXT into tokens\n",
    "        #print(sub_tokens)#(test)\n",
    "\n",
    "    # The -3 accounts for [CLS], [SEP] and [SEP]\n",
    "    max_tokens_for_doc = max_seq_length - len(query_tokens) - 3\n",
    "       #print(max_seq_length)(test)\n",
    "       #print(len(query_tokens))(test)\n",
    "    # We can have documents that are longer than the maximum sequence length.\n",
    "    # To deal with this we do a sliding window approach, where we take chunks\n",
    "    # of the up to our max length with a stride of `doc_stride`.\n",
    "    _DocSpan = collections.namedtuple(  # pylint: disable=invalid-name\n",
    "        \"DocSpan\", [\"start\", \"length\"])\n",
    "    doc_spans = []\n",
    "    start_offset = 0\n",
    "    while start_offset < len(all_doc_tokens):\n",
    "        length = len(all_doc_tokens) - start_offset\n",
    "        if length > max_tokens_for_doc:\n",
    "            length = max_tokens_for_doc\n",
    "        doc_spans.append(_DocSpan(start=start_offset, length=length))\n",
    "        if start_offset + length == len(all_doc_tokens):\n",
    "            break\n",
    "        start_offset += min(length, doc_stride)\n",
    "\n",
    "    #input_ids = torch.tensor([0], dtype=torch.long)\n",
    "    #input_mask = torch.tensor([0], dtype=torch.long)\n",
    "    #segment_ids = torch.tensor([0], dtype=torch.long)\n",
    "    #cls_index = torch.tensor([0], dtype=torch.long)\n",
    "    #p_mask = torch.tensor([0], dtype=torch.float)\n",
    "    #example_index = torch.arange(input_ids.size(0), dtype=torch.long)\n",
    "    #tokens = []\n",
    "    for (doc_span_index, doc_span) in enumerate(doc_spans):\n",
    "        tokens = []\n",
    "        token_to_orig_map = {}\n",
    "        token_is_max_context = {}\n",
    "        segment_ids = []\n",
    "\n",
    "        # p_mask: mask with 1 for token than cannot be in the answer (0 for token which can be in an answer)\n",
    "        # Original TF implem also keep the classification token (set to 0) (not sure why...)\n",
    "        p_mask = []\n",
    "\n",
    "        # CLS token at the beginning\n",
    "        if not cls_token_at_end:\n",
    "            tokens.append(cls_token)\n",
    "            segment_ids.append(cls_token_segment_id)\n",
    "            p_mask.append(0)\n",
    "            cls_index = 0\n",
    "\n",
    "        # Query\n",
    "        for token in query_tokens:\n",
    "            tokens.append(token)\n",
    "            segment_ids.append(sequence_a_segment_id)\n",
    "            p_mask.append(1)\n",
    "\n",
    "        # SEP token\n",
    "        tokens.append(sep_token)\n",
    "        segment_ids.append(sequence_a_segment_id)\n",
    "        p_mask.append(1)\n",
    "\n",
    "        # Paragraph\n",
    "        for i in range(doc_span.length):\n",
    "            split_token_index = doc_span.start + i\n",
    "            #print(split_token_index)******\n",
    "            token_to_orig_map[len(tokens)] = tok_to_orig_index[split_token_index]\n",
    "\n",
    "            is_max_context = _check_is_max_context(doc_spans, doc_span_index,\n",
    "                                                   split_token_index)\n",
    "            token_is_max_context[len(tokens)] = is_max_context#type:boolean\n",
    "\n",
    "            tokens.append(all_doc_tokens[split_token_index])\n",
    "            segment_ids.append(sequence_b_segment_id)\n",
    "            p_mask.append(0)\n",
    "        paragraph_len = doc_span.length\n",
    "        #print(paragraph_len)(test)\n",
    "\n",
    "        # SEP token\n",
    "        tokens.append(sep_token)\n",
    "        segment_ids.append(sequence_b_segment_id)\n",
    "        p_mask.append(1)\n",
    "\n",
    "        # CLS token at the end\n",
    "        if cls_token_at_end:\n",
    "            tokens.append(cls_token)\n",
    "            segment_ids.append(cls_token_segment_id)\n",
    "            p_mask.append(0)\n",
    "            cls_index = len(tokens) - 1  # Index of classification token\n",
    "\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        #print(input_ids)\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "        # tokens are attended to.\n",
    "        input_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
    "        #print(input_mask)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        while len(input_ids) < max_seq_length:\n",
    "            input_ids.append(pad_token)\n",
    "            input_mask.append(0 if mask_padding_with_zero else 1)\n",
    "            segment_ids.append(pad_token_segment_id)\n",
    "            p_mask.append(1)\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "    input_ids = torch.tensor([input_ids], dtype=torch.long)\n",
    "    input_mask = torch.tensor([input_mask], dtype=torch.long)\n",
    "    segment_ids = torch.tensor([segment_ids], dtype=torch.long)\n",
    "    cls_index = torch.tensor([cls_index], dtype=torch.long)\n",
    "    p_mask = torch.tensor([p_mask], dtype=torch.float)\n",
    "    example_index = torch.arange(input_ids.size(0), dtype=torch.long)\n",
    "    data = TensorDataset(input_ids, input_mask, segment_ids,\n",
    "                            example_index, cls_index, p_mask)\n",
    "\n",
    "\n",
    "    ##print(\"*** Example ***\")\n",
    "    # print(\"doc_span_index: %s\" % (doc_span_index))\n",
    "    ##print(\"tokens: %s\" % \" \".join(tokens))\n",
    "    # print(\"token_to_orig_map: %s\" % \" \".join([\n",
    "    #                 \"%d:%d\" % (x, y) for (x, y) in token_to_orig_map.items()]))\n",
    "    # print(\"token_is_max_context: %s\" % \" \".join([\n",
    "    #                 \"%d:%s\" % (x, y) for (x, y) in token_is_max_context.items()\n",
    "    #             ]))\n",
    "    # print(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
    "    # print(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
    "    # print(\"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
    "\n",
    "    return data, tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DRCDDataSet class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#此部分為設定訓練模型 對照LEEMENG文章第二點\n",
    "\"\"\"\n",
    "實作一個可以用來讀取訓練 / 測試集的 Dataset，這是你需要徹底了解的部分。\n",
    "此 Dataset 每次將 tsv 裡的一筆成對句子轉換成 BERT 相容的格式，並回傳 3 個 tensors：\n",
    "- tokens_tensor：兩個句子合併後的索引序列，包含 [CLS] 與 [SEP]\n",
    "- segments_tensor：可以用來識別兩個句子界限的 binary tensor\n",
    "- label_tensor：將分類標籤轉換成類別索引的 tensor, 如果是測試集則回傳 None\n",
    "\"\"\"\n",
    "    \n",
    "class DRCDDataset(Dataset):\n",
    "    # 讀取前處理後的 tsv 檔並初始化一些參數\n",
    "    def __init__(self, mode, tokenizer):\n",
    "        assert mode in [\"train\", \"test\"]  # 一般訓練你會需要 dev set\n",
    "        self.mode = mode\n",
    "        # 大數據你會需要用 iterator=True\n",
    "        self.df = pd.read_csv(mode + \".tsv\", sep=\"\\t\").fillna(\"\")\n",
    "        self.len = len(self.df)\n",
    "        self.tokenizer = tokenizer  # 我們將使用 BERT tokenizer\n",
    "        #self.label_map={}\n",
    "            #for i in len(df_train):\n",
    "              #updata={answer:i}\n",
    "              #self.label_map.update(updata)\n",
    "\n",
    "    # 定義回傳一筆訓練 / 測試數據的函式\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == \"test\":\n",
    "            question, document = self.df.iloc[idx, :2].values\n",
    "            label_tensor = None\n",
    "        else:\n",
    "            question, document, answer = self.df.iloc[idx, :].values\n",
    "            # 將 label 文字也轉換成索引方便轉換成 tensor\n",
    "            #answer_id = answer\n",
    "              \n",
    "            #label_tensor=tf.string_to_number(answer,out_type=None,name=None)\n",
    "            #label_tensor=tf.convert_to_tensor(answer,dtype=None,dtype_hint=None,name=None)\n",
    "            #answer_id= self.tokenizer.tokenize(answer)\n",
    "            token_answer = self.tokenizer.tokenize(answer)\n",
    "            answer_ids = self.tokenizer.convert_tokens_to_ids(token_answer)\n",
    "            label_tensor = torch.Tensor(answer_ids)\n",
    "            #label_tensor = torch.tensor(answer_id)\n",
    "            #label_tensor= answer\n",
    "\n",
    "\n",
    "        # 建立第一個句子的 BERT tokens 並加入分隔符號 [SEP]\n",
    "        word_pieces = [\"[CLS]\"]\n",
    "        tokens_question = self.tokenizer.tokenize(question)\n",
    "        word_pieces += tokens_question + [\"[SEP]\"]\n",
    "        len_a = len(word_pieces)\n",
    "        \n",
    "        # 第二個句子的 BERT tokens\n",
    "        tokens_document = self.tokenizer.tokenize(document)\n",
    "        word_pieces += tokens_document + [\"[SEP]\"]\n",
    "        len_b = len(word_pieces) - len_a\n",
    "        \n",
    "        # 將整個 token 序列轉換成索引序列\n",
    "        ids = self.tokenizer.convert_tokens_to_ids(word_pieces)\n",
    "        tokens_tensor = torch.Tensor(ids)\n",
    "        \n",
    "        # 將第一句包含 [SEP] 的 token 位置設為 0，其他為 1 表示第二句\n",
    "        segments_tensor = torch.cuda.LongTensor([0] * len_a + [1] * len_b)#, \n",
    "                                      #  dtype=torch.long)\n",
    "        \n",
    "        return (tokens_tensor, segments_tensor, label_tensor)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#此部分為設定訓練模型 對照LEEMENG文章第二點\n",
    "\n",
    "# 這個函式的輸入 `samples` 是一個 list，裡頭的每個 element 都是\n",
    "# 剛剛定義的 `FakeNewsDataset` 回傳的一個樣本，每個樣本都包含 3 tensors：\n",
    "# - tokens_tensor\n",
    "# - segments_tensor\n",
    "# - label_tensor\n",
    "# 它會對前兩個 tensors 作 zero padding，並產生前面說明過的 masks_tensors\n",
    "def create_mini_batch(samples):\n",
    "    tokens_indexes = [s[0] for s in samples]\n",
    "    tokens_indexes_tensors = torch.stack(tokens_indexes).contiguous()\n",
    "    tokens_index_tensors=torch.cuda.LongTensor(tokens_indexes_tensors)\n",
    "    segments_indexes = [s[1] for s in samples]\n",
    "    segments_indexes_tensors = torch.stack(segments_indexes).contiguous()\n",
    "    segments_index_tensors=torch.cuda.LongTensor(segments_indexes_tensors)\n",
    "\n",
    "    \n",
    "    # 訓練集有 labels(answer)\n",
    "    if samples[0][2] is not None:\n",
    "        label_tensor = [s[2] for s in samples]\n",
    "    else:\n",
    "        label_tensor = None\n",
    "    \n",
    "    # zero pad 到同一序列長度\n",
    "    tokens_index_tensors = pad_sequence(tokens_index_tensors, \n",
    "                                  batch_first=True).cuda()\n",
    "    segments_index_tensors = pad_sequence(segments_index_tensors, \n",
    "                                    batch_first=True).cuda()\n",
    "    \n",
    "    #label_tensor= pad_sequence(label_tensor, \n",
    "                                    #batch_first=True)\n",
    "    \n",
    "    # attention masks，將 tokens_tensors 裡頭不為 zero padding\n",
    "    # 的位置設為 1 讓 BERT 只關注這些位置的 tokens\n",
    "    masks_tensors = torch.zeros(tokens_index_tensors.shape, \n",
    "                                dtype=torch.long,device='cuda')\n",
    "    \n",
    "    masks_tensors = masks_tensors.masked_fill(\n",
    "        tokens_index_tensors != 0, 1)\n",
    "    masks_tensors=masks_tensors.cuda()\n",
    "    return tokens_index_tensors, segments_index_tensors, masks_tensors, label_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因為要我們今天要跑的是中文QA 所以只有Bert可以用\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device('cuda:0')\n",
    "checkpoint = 'bert-chinese-qa'\n",
    "config_class, model_class, tokenizer_class = BertConfig, BertForQuestionAnswering, BertTokenizer\n",
    "model = model_class.from_pretrained(checkpoint).to(device)\n",
    "tokenizer = tokenizer_class.from_pretrained('bert-base-chinese', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#此部分為設定訓練模型 對照LEEMENG文章第一點\n",
    "\n",
    "# df_train = pd.read_csv(\"DRCDtraining_output3.csv\",encoding=\"MS950\")\n",
    "# @tianjianjiang: where was `DRCDtraining_output3.csv`?\n",
    "# I guess there were some preprocessed files in the GDrive that wasn't explicitly referenced in this notebook.\n",
    "# So I use the original one instead.\n",
    "df_train = pd.read_csv(\n",
    "    f'{DATA_DIR_P}/BERT-Practice/DRCDtraining_output.csv',\n",
    "    encoding='MS950',\n",
    "    header=None,\n",
    "    names=['document', 'question', 'answer'],\n",
    "    error_bad_lines=False\n",
    "  )\n",
    "\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只用 1% 訓練數據看看 BERT 對少量標註數據有多少幫助\n",
    "SAMPLE_FRAC = 1.00\n",
    "df_train = df_train.sample(frac=SAMPLE_FRAC, random_state=9527)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I presume the snippet below was for the missing `DRCDtraining_output3.csv`\n",
    "# 去除不必要的欄位並重新命名兩標題的欄位名\n",
    "# df_train = df_train.reset_index()\n",
    "# df_train = df_train.loc[:, ['document ', ' question ',' answer']]\n",
    "# df_train.columns = ['document', 'question', 'answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 剔除過長的樣本以避免 BERT 無法將整個輸入序列放入記憶體不多的 GPU\n",
    "MAX_LENGTH = 256\n",
    "MAX_LENGTHQUE = 220\n",
    "\n",
    "df_train = df_train[~(df_train.document.apply(lambda x : len(x)) > MAX_LENGTH)]\n",
    "df_train = df_train[~(df_train.question.apply(lambda x : len(x)) > MAX_LENGTHQUE)]\n",
    "# idempotence, 將處理結果另存成 tsv 供 PyTorch 使用\n",
    "df_train.to_csv(\"train.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"訓練樣本數：\", len(df_train))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化一個專門讀取訓練樣本的 Dataset，使用中文 BERT 斷詞\n",
    "trainset = DRCDDataset(\"train\", tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 0\n",
    "\n",
    "# 將原始文本拿出做比較\n",
    "document , question, answer = trainset.df.iloc[sample_idx].values\n",
    "\n",
    "# 利用剛剛建立的 Dataset 取出轉換後的 id tensors\n",
    "tokens_tensor, segments_tensor, label_tensor = trainset[sample_idx]\n",
    "\n",
    "# 將 tokens_tensor 還原成文本\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokens_tensor.tolist())\n",
    "combined_text = \"\".join(tokens)\n",
    "\n",
    "# 渲染前後差異，毫無反應就是個 print。可以直接看輸出結果\n",
    "print(f\"\"\"[原始文本]\n",
    "句子 1：{document}\n",
    "句子 2：{question}\n",
    "分類  ：{answer}\n",
    "\n",
    "--------------------\n",
    "\n",
    "[Dataset 回傳的 tensors]\n",
    "tokens_tensor  ：{tokens_tensor}\n",
    "\n",
    "segments_tensor：{segments_tensor}\n",
    "\n",
    "label_tensor   ：{label_tensor}\n",
    "\n",
    "--------------------\n",
    "\n",
    "[還原 tokens_tensors]\n",
    "{combined_text}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化一個每次回傳 64 個訓練樣本的 DataLoader\n",
    "# 利用 `collate_fn` 將 list of samples 合併成一個 mini-batch 是關鍵\n",
    "BATCH_SIZE = 1\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, \n",
    "                         collate_fn=create_mini_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Always check the warnings\n",
    "\n",
    "1. Click \"View runtime logs\"\n",
    "2. Read them carefully\n",
    "3. Search for similar issues and solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#此部分為實際訓練模型 對照LEEMENG文章第四點\n",
    "#檢查設定\n",
    "#model.config()\n",
    "%%time\n",
    "\n",
    "# 訓練模式\n",
    "model.train()\n",
    "\n",
    "# 使用 Adam Optim 更新整個分類模型的參數\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "EPOCHS = 6  # 幸運數字\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    #cnt=0\n",
    "    for data in trainloader:\n",
    "    # if cnt >len(trainloader)-1:\n",
    "    #   break\n",
    "    \n",
    "      for i in data:\n",
    "        print(data[0][i])\n",
    "        #tokens_tensor=data[0][i].to(device)\n",
    "        #segments_tensor=data[1][i].to(device)\n",
    "        #masks_tensor=data[2][i].to(device)\n",
    "        #label_tensor=data[3][i].to(device)\n",
    "        #tokens_tensors, segments_tensors, \\\n",
    "        #masks_tensors, label_tensor = (t.to(device) for t in data)\n",
    "        #start_position=label_tensor[0]\n",
    "        #end_position=label_tensor[len(label_tensor)-1]\n",
    "    \n",
    "\n",
    "        # 將參數梯度歸零\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(input_ids=tokens_index_tensors, \n",
    "                        token_type_ids=segments_index_tensors, \n",
    "                        attention_mask=masks_tensors, \n",
    "                        start_position=start_position,end_position=end_position)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        # 紀錄當前 batch loss\n",
    "        running_loss += loss.item()\n",
    "    #cnt=cnt+1    \n",
    "    # 計算分類準確率\n",
    "    _, acc = get_predictions(model, trainloader, compute_acc=True)\n",
    "\n",
    "    print('[epoch %d] loss: %.3f, acc: %.3f' %\n",
    "          (epoch + 1, running_loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To-be-determined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutctextver2(datatext,dataquestion,plen,lookback,pstartlen,answerget,ans):\n",
    "    if answerget==True and pstartlen>=len(datatext[0]):\n",
    "        print(dataquestion)\n",
    "        print(ans)\n",
    "        return\n",
    "    elif pstartlen>=len(datatext[0]) and answerget==False:\n",
    "        print(dataquestion)\n",
    "        print('[UNKNOWN]')\n",
    "        return\n",
    "    else:\n",
    "        cutt=datatext[0][pstartlen:pstartlen+plen]\n",
    "        #print(cutt)\n",
    "        data, tokens = convert_examples_to_features(tokenizer=tokenizer, question_text=dataquestion, doc_tokens=cutt)\n",
    "        start, end = evaluate(data, model, tokenizer)\n",
    "        knowans=\"\".join(tokens[start[0]: end[0]+1])\n",
    "        if (knowans!='[CLS]')and knowans!=''and knowans[0:5]!='[CLS]':\n",
    "          answerget=True\n",
    "          ansisget=knowans\n",
    "          #ans=knowans\n",
    "          return cutctextver2(datatext,dataquestion,plen,lookback,pstartlen+lookback,answerget,ansisget)\n",
    "        return cutctextver2(datatext,dataquestion,plen,lookback,pstartlen+lookback,answerget,ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(PdContestQuestion_A)):\n",
    "    context=np.array(PdContestQuestion_A[i:i+1]['DTEXT'])\n",
    "    dfr=np.array(PdContestQuestion_A[i:i+1])\n",
    "    print(dfr[0][0])\n",
    "    print(\"Q\"+str(i+1)+'.'+context[0])\n",
    "    for j in range(len(dfr[0][2])):\n",
    "        question=dfr[0][2][j]['QTEXT']\n",
    "        print(question[3:len(question)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(PdContestQuestion_A)):\n",
    "    context=np.array(PdContestQuestion_A[i:i+1]['DTEXT'])\n",
    "    dfr=np.array(PdContestQuestion_A[i:i+1])\n",
    "    for j in range(len(dfr[0][2])):\n",
    "        question=dfr[0][2][j]['QTEXT']\n",
    "        X.append([context,questioncut])\n",
    "print(X[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexttest=np.array(PdContestQuestion_A[0:1]['DTEXT'])\n",
    "dft=np.array(PdContestQuestion_A[0:1])\n",
    "question=dft[0][2][1]['QTEXT']\n",
    "print(dft[0][2][1]['QTYPE'])\n",
    "ans=\"\"\n",
    "cutctextver2(contexttest,question,256,50,0,False,ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testver3\n",
    "ans=\"\"\n",
    "for i in range(0,len(PdContestQuestion_A)):\n",
    "    context=np.array(PdContestQuestion_A[i:i+1]['DTEXT'])\n",
    "    dfr=np.array(pddata[i:i+1])\n",
    "    print(dfr[0][0])\n",
    "    print(\"Q\"+str(i+1)+'.'+context[0])\n",
    "    for j in range(len(dfr[0][2])):\n",
    "        print(dfr[0][2][j]['QTYPE'])\n",
    "        question=dfr[0][2][j]['QTEXT']\n",
    "        cutctextver2(context,question,256,50,0,False,ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=\"\"\n",
    "for i in range(0,len(pddata)):\n",
    "    context=np.array(pddata[i:i+1]['DTEXT'])\n",
    "    dfr=np.array(pddata[i:i+1])\n",
    "    print(dfr[0][0])\n",
    "    print(\"Q\"+str(i+1)+'.'+context[0])\n",
    "    for j in range(len(dfr[0][2])):\n",
    "        question=dfr[0][2][j]['QTEXT']\n",
    "        cutctextver2(context,question,256,50,0,False,ans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
